{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.3 Single-variate Linear Regression without Bias Term\n",
    "\n",
    "## Programming Assignment.3-10 Mini-batch Gradient Descent Method\n",
    "\n",
    "PA 3-10에서는 n개의 data sample을 이용하여 $\\theta$를 학습시키는 Mini-batch Gradient Descent Method(이하 MGDM)를 구현합니다.\n",
    "\n",
    "이때 n을 mini-batch size또는 batch size라고 부르고, dataset 전체를 이용하는 batch gradient descent method와 마찬가지로,  \n",
    "cost를 이용하여 $\\theta$를 학습시킵니다.\n",
    "\n",
    "\n",
    "이때 SGDM과 마찬가지로 MGDM에도 with replacment, without replacement를 적용할 수 있습니다.  \n",
    "따라서 batch를 만들어주는 함수를 구현하는 과정을 포함하여 PA 3-10은 다음과 같은 단계로 진행됩니다.\n",
    "\n",
    "<ul>\n",
    "    <li> Step.1 Batch Extraction </li>\n",
    "    <li> Step.2 MGDM without Replacement </li>\n",
    "    <li> Step.3 MGDM with Replacement </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "utils_path = os.path.dirname(os.path.abspath(__name__)) + '/../utils/'\n",
    "if utils_path not in sys.path:    \n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "import basic_nodes as nodes\n",
    "from LR_dataset_generator import LR_dataset_generator\n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PA 3-09와 마찬가지로 default dataset을 만들고,  \n",
    "PA 3-08과 같이 model과 mean_node를 이용한 cost function을 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Start Your Code(Dataset Preparation) #####\n",
    "\n",
    "##### End Your Code(Dataset Preparation) #####\n",
    "\n",
    "\n",
    "##### Start Your Code(Model/Cost Implementation) #####\n",
    "\n",
    "##### End Your Code(Model/Cost Implementation) #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step.1 Batch Extraction\n",
    "\n",
    "batch size를 argument로 입력받아 mini-batch를 return해주는 get_data_batch 함수를 구현합니다.\n",
    "\n",
    "이때 전체 dataset에 들어있는 data sample의 개수가 batch size로 나누어 떨어지지 않는 경우를 표현하면 다음과 같습니다.\n",
    "<img src='./imgs/3_10_01.png' width=800>\n",
    "즉, 마지막 mini-batch에 대해서는 위와 같이 구현해줍니다.\n",
    "\n",
    "***\n",
    "**Programming**  \n",
    "위의 내용을 바탕으로 get_data_batch 함수를 구현하세요.  \n",
    "이 함수의 input/output은 다음과 같습니다.\n",
    "- INPUT : dataset, batch index\n",
    "- OUTPUT : mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_batch(dataset, batch_idx):\n",
    "    ##### Start Your Code(Batch Extraction) #####\n",
    "    \n",
    "    ##### End Your Code(Batch Extraction) #####\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 batch의 개수를 구하는 과정은 다음과 같습니다.\n",
    "\n",
    "전체 data sample의 개수가 mini-batch size로 나누어 떨어지지 않는 경우를 위해 다음과 같이 mini-batch의 개수는 ceiling을 이용하여 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data sample :  100\n",
      "(# data sample)/(Batch Size) :  6.25\n",
      "After ceiling :  7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "print(\"# data sample : \", dataset.shape[0])\n",
    "print(\"(# data sample)/(Batch Size) : \", dataset.shape[0]/batch_size)\n",
    "print(\"After ceiling : \", int(np.ceil(dataset.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step.2 MGDM without Replacement\n",
    "\n",
    "PA 3-09와 마찬가지로 replacement를 하지 않는 MGDM는 for loop을 이용하여 학습을 진행합니다.  \n",
    "다만 달라지는 점은 data sample에 접근하는 것이 아니라 for loop을 통해 batch index를 이용한다는 점입니다.\n",
    "\n",
    "위의 mini-batch 그림을 참고하면 전체 mini-batch의 개수만큼 for loop이 돌고, 각 for loop에서는 batch index를 이용하게 됩니다.\n",
    "\n",
    "***\n",
    "**Programming**  \n",
    "get_data_batch 함수와 PA 3-08의 코드를 참고하여 replacement가 없는 MGDM을 구현하세요.  \n",
    "이때 학습조건은 다음과 같습니다.\n",
    "- initial theta = 0.1\n",
    "- learning rate = 0.01\n",
    "- total epoch = 20\n",
    "- batch size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Start Your Code(Learning Preparation) #####\n",
    "th = \n",
    "lr = \n",
    "epochs = \n",
    "\n",
    "batch_size = \n",
    "n_batch = \n",
    "##### End Your Code(Learning Preparation) #####\n",
    "\n",
    "th_list = []\n",
    "loss_list = []\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    ##### Start Your Code(Random Shuffling) #####\n",
    "    \n",
    "    ##### Start Your Code(Random Shuffling) #####\n",
    "    \n",
    "    \n",
    "    ##### Start Your Code(MGDM without Replacement) #####\n",
    "    \n",
    "    ##### Start Your Code(MGDM without Replacement) #####\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize = (15,8))\n",
    "fig.subplots_adjust(hspace = 0.3)\n",
    "ax[0].plot(th_list)\n",
    "ax[1].plot(loss_list)\n",
    "ax[0].tick_params(axis = 'both', labelsize = 20)\n",
    "ax[1].tick_params(axis = 'both', labelsize = 20)\n",
    "ax[0].set_title(r'$\\theta$', fontsize = 30)\n",
    "ax[1].set_title(r'$\\mathcal{L}$', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "<img src='./imgs/3_10_02.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step.3 MGDM with Replacement\n",
    "\n",
    "replacement를 이용하는 MGDM은 PA 3-09와 마찬가지로 random sampling을 이용하여 mini-batch를 뽑습니다.\n",
    "\n",
    "이때 달라지는 점은 random choice의 size입니다.\n",
    "그리고 PA 3-09와 마찬가지로 epoch보단 iteration이라는 표현이 더 적절합니다.\n",
    "\n",
    "***\n",
    "**Programming**  \n",
    "다음 조건에서 replacement를 이용하는 MGDM을 구현하세요.\n",
    "- initial theta = 0.1\n",
    "- learning rate = 0.01\n",
    "- batch size = 8\n",
    "- total iteration = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Start Your Code(Learning Preparation) #####\n",
    "th = \n",
    "lr = \n",
    "\n",
    "batch_size = \n",
    "iterations = \n",
    "##### End Your Code(Learning Preparation) #####\n",
    "\n",
    "th_list = []\n",
    "loss_list = []\n",
    "    \n",
    "for iteration in range(iterations):\n",
    "    ##### Start Your Code(Random Sampling) #####\n",
    "    \n",
    "    ##### Start Your Code(Random Sampling) #####\n",
    "    \n",
    "    \n",
    "    ##### Start Your Code(MGDM with Replacement) #####\n",
    "    \n",
    "    ##### Start Your Code(MGDM with Replacement) #####\n",
    "    \n",
    "fig, ax = plt.subplots(2, 1, figsize = (15,8))\n",
    "fig.subplots_adjust(hspace = 0.3)\n",
    "ax[0].plot(th_list)\n",
    "ax[1].plot(loss_list)\n",
    "ax[0].tick_params(axis = 'both', labelsize = 20)\n",
    "ax[1].tick_params(axis = 'both', labelsize = 20)\n",
    "ax[0].set_title(r'$\\theta$', fontsize = 30)\n",
    "ax[1].set_title(r'$\\mathcal{L}$', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "<img src='./imgs/3_10_03.png' width=800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
