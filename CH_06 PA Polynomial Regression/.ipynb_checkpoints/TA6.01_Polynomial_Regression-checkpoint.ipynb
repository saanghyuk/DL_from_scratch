{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.6.01 Polynomial Regression\n",
    "이번 PA 6.01에서는 Polynomial Regression을 진행하는데<br>\n",
    "실제 M차원에 따라서 어떻게 학습되는지 확인할 것입니다<br>\n",
    "모델은 다음과 같이 형성됩니다\n",
    "$$\\hat{y} =\\theta_{m}x^m +  \\theta_{m-1}x^{m-1} +...+ \\theta_{1}x^1 +  \\theta_{0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import copy\n",
    "import basic_nodes as nodes\n",
    "import affine_MSE\n",
    "from tqdm import trange\n",
    "def get_data_batch(dataset, batch_idx, batch_size, n_batch):\n",
    "    if batch_idx is n_batch -1:\n",
    "        batch = dataset[batch_idx*batch_size:]\n",
    "    else:\n",
    "        batch = dataset[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    return batch\n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.1 Dataset Generator\n",
    "200개의 Data Sample을 생성합니다<br>\n",
    "Input x_data는 [0.05 ~ 1 - 0.05]의 범위에서 생성합니다(np.linspace 사용)<br>\n",
    "y_data는 sin함수를 따라서 만들며 x_data를 통한 sin함수에 Noise를 추가합니다<br>\n",
    "h_oreder는 3차원으로 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Dataset Preparation ###\n",
    "n_sample = 200\n",
    "h_order = 3\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1-0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1)\n",
    "### End Dataset Preparation ###\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.2 Parameter 설정\n",
    "학습에 필요한 Parameter를 설정하고<br>\n",
    "5장 Multi-Variate-Linear-Regression에서 사용했던<br>\n",
    "Affine_Function과 MSE_Cost를 import하여 사용합니다<br>\n",
    "\n",
    "* batch_size = 32\n",
    "* epochs = 300000\n",
    "* lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "### Start Parameter Set ###\n",
    "epochs, lr = 300000, 0.01\n",
    "\n",
    "### End Parameter Set ###\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.3 Learning\n",
    "mini-batch를 통한 Data를 MVLR에서 Learning했던 것과 동일하게<br>\n",
    "Learning을 진행한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다만 $\\theta$가 데이터셋을 따라 자리 잡기까지<br>\n",
    "시간이 굉장히 오래 걸립니다<br>\n",
    "따라서 밤에 실행후 주무시고 일어나시면 될 것같습니다<br>\n",
    "보여드릴 코드는 h_order를 [3, 5, 7, 11] 4가지 Case를 통해서<br>\n",
    "동일한 Epoch동안 어떻게 학습되는지를 관찰 할 것인데<br>\n",
    "시간이 너무 오래 걸린다면 h_order 한가지만 해보셔도 됩니다<br>\n",
    "또한 Epoch를 300000이 아니라 줄이시고 해보셔도 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4601/300000 [00:05<05:47, 849.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9614975e30fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx, batch_size, n_sample)\n",
    "        X, Y = batch[:,:-1], batch[:,-1]\n",
    "        Pred = affine.forward(X)\n",
    "        J = cost.forward(Y, Pred)\n",
    "        \n",
    "        dPred = cost.backward()\n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.4 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h3.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 5\n",
    "다른 조건들은 동일하게 진행하고 h_order를 5로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 200\n",
    "h_order = 5\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1 - 0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1) + 0.2*np.random.normal(0, 1, size = (n_sample,1))\n",
    "\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "\n",
    "epochs, lr = 300000, 0.01\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx, batch_size, n_sample)\n",
    "        X, Y = batch[:,:-1], batch[:,-1]\n",
    "        Pred = affine.forward(X)\n",
    "        J = cost.forward(Y, Pred)\n",
    "        \n",
    "        dPred = cost.backward()\n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h5.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 7\n",
    "다른 조건들은 동일하게 진행하고 h_order를 7로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 200\n",
    "h_order = 7\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1 - 0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1) + 0.2*np.random.normal(0, 1, size = (n_sample,1))\n",
    "\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "\n",
    "epochs, lr = 300000, 0.01\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx, batch_size, n_sample)\n",
    "        X, Y = batch[:,:-1], batch[:,-1]\n",
    "        Pred = affine.forward(X)\n",
    "        J = cost.forward(Y, Pred)\n",
    "        \n",
    "        dPred = cost.backward()\n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h7.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 11\n",
    "다른 조건들은 동일하게 진행하고 h_order를 11로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 200\n",
    "h_order = 11\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1 - 0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1) + 0.2*np.random.normal(0, 1, size = (n_sample,1))\n",
    "\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "\n",
    "epochs, lr = 300000, 0.01\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx, batch_size, n_sample)\n",
    "        X, Y = batch[:,:-1], batch[:,-1]\n",
    "        Pred = affine.forward(X)\n",
    "        J = cost.forward(Y, Pred)\n",
    "        \n",
    "        dPred = cost.backward()\n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h11.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Without Noise\n",
    "기존의 데이터셋에서 노이즈를 제거한 모습을 보게 되면<br>\n",
    "다음과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 200\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1 - 0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1) #+ 0.2*np.random.normal(0, 1, size = (n_sample,1))\n",
    "plt.scatter(x_data1,y_data,color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "결과를 비교해보면 h_order 가 3일때가 Dataset에 가장 맞는 학습 결과로 볼수 있다<br>\n",
    "강의에서 소개했던 Pattern Recognition and Machine learning을 보게되면<br>\n",
    "아래 사진과 같이 h_order가 높아질수록 overfitting의 위험성이 높아진다<br>\n",
    "하지만 h_order 11에서도 overfitting이 크게 발생하지 않았다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/6_5.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 이유는 다음의 그림과 같이 많은 데이터셋을 통해서<br>\n",
    "학습을 진행했기 때문에 Overfitting의 발생을 억제한 것이다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/6_6.png' width = 600>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
