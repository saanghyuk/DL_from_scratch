{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.9.04 SVLoR for Several Samples\n",
    "\n",
    "PA 9.04에서는 Several Samples를 통해서<br>\n",
    "SVLoR을 구현합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import basic_nodes as nodes\n",
    "\n",
    "np.random.seed(0)\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 30\n",
    "mpl.rcParams['axes.titlesize'] = 40\n",
    "mpl.rcParams['legend.fontsize'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.1 Affine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    ### Start\n",
    "    def __init__(self):\n",
    "        self._feature_dim = \n",
    "        self._Th = \n",
    "        \n",
    "        self.node_imp()\n",
    "        self.random_initialization()\n",
    "\n",
    "    def node_imp(self):\n",
    "        self._node1 = nodes.mul_node()\n",
    "        self._node2 = nodes.plus_node()\n",
    "    \n",
    "    def random_initialization(self):\n",
    "        r_feature_dim = \n",
    "        self._Th = np.random.uniform(low = ,\n",
    "                                     high = ,\n",
    "                                     size = )\n",
    "    \n",
    "    def forward(self,X):\n",
    "        self._Z1 = \n",
    "        self._Z2 =\n",
    "\n",
    "        return self._Z2\n",
    "    \n",
    "    def backward(self, dZ, lr):\n",
    "        dTh0, dZ1 = \n",
    "        dTh1, dX = \n",
    "\n",
    "        self._Th[1] = \n",
    "        self._Th[0] = \n",
    "    ### End\n",
    "    def get_Th(self):\n",
    "        return self._Th "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.2 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    ### Start\n",
    "    def __init__(self):\n",
    "        self._Pred = \n",
    "    \n",
    "    def forward(self, Z):\n",
    "        self._Pred = \n",
    "        return self._Pred\n",
    "    \n",
    "    def backward(self, dPred):\n",
    "        partial =\n",
    "        dZ =\n",
    "        return dZ\n",
    "    ### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.3 BinaryCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy_Cost:\n",
    "    ### Start\n",
    "    def __init__(self):\n",
    "        self._Y, self._Pred = None, None\n",
    "        self._mean_node =  nodes.mean_node()\n",
    "    \n",
    "    def forward(self, Y, Pred):\n",
    "        self._Y, self._Pred = \n",
    "        Loss = \n",
    "        J =\n",
    "        return J\n",
    "    \n",
    "    def backward(self):\n",
    "        dLoss = \n",
    "        dPred =\n",
    "        return dPred\n",
    "    ### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.4 SVLoR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVLoR:\n",
    "    ### Start\n",
    "    def __init__(self):\n",
    "        self._feature_dim = \n",
    "        self._affine = \n",
    "        self._sigmoid = \n",
    "\n",
    "    def forward(self, X):\n",
    "        Z = \n",
    "        Pred =\n",
    "        return Pred\n",
    "    \n",
    "    def backward(self, dPred, lr):\n",
    "        dZ = \n",
    "        self._affine.backward(dZ, lr)\n",
    "    ### End\n",
    "    def  get_Th(self):\n",
    "        return self._affine.get_Th()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.5 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_tracker():\n",
    "    global iter_idx, check_freq\n",
    "    global th_accum, model\n",
    "\n",
    "    if iter_idx % check_freq == 0:\n",
    "        th_accum = np.hstack((th_accum, model.get_Th()))\n",
    "        cost_list.append(J)\n",
    "    iter_idx += 1\n",
    "def result_visualizer():\n",
    "    global th_accum, cost_list\n",
    "    fig,ax = plt.subplots(2, 1, figsize = (30,10))\n",
    "    fig.subplots_adjust(hspace = 0.3)\n",
    "    ax[0].set_title(r'$\\vec{\\theta}$' + 'Update ')\n",
    "\n",
    "    ax[0].plot(th_accum[1,:], label = r'$\\theta_{1}$')\n",
    "    ax[0].plot(th_accum[0,:], label = r'$\\theta_{0}$')\n",
    "\n",
    "    ax[0].legend()\n",
    "    iter_ticks = np.linspace(0,th_accum.shape[1],10).astype(np.int)\n",
    "    ax[0].set_xticks(iter_ticks)\n",
    "\n",
    "    ax[1].set_title('Cost')\n",
    "    ax[1].plot(cost_list)\n",
    "    ax[1].set_xticks(iter_ticks)\n",
    "\n",
    "    n_pred = 1000\n",
    "    fig,ax = plt.subplots(figsize = (30,10))\n",
    "    ax.set_title('Predictor Update')\n",
    "    ax.scatter(data[:,1], data[:,-1])\n",
    "\n",
    "    ax_idx_arr = np.linspace(0,len(cost_list)-1,n_pred).astype(np.int)\n",
    "    cmap = cm.get_cmap('rainbow',lut = len(ax_idx_arr))\n",
    "\n",
    "    x_pred = np.linspace(np.min(data[:,1]),np.max(data[:,1]),1000)\n",
    "    for ax_cnt, ax_idx in enumerate(ax_idx_arr):\n",
    "        z = th_accum[1, ax_idx] * x_pred + th_accum[0,ax_idx]\n",
    "        a = 1/(1 + np.exp(-1 * z))\n",
    "        ax.plot(x_pred, a, color = cmap(ax_cnt),alpha = 0.2)\n",
    "\n",
    "    y_ticks = np.round(np.linspace(0, 1, 7),2)\n",
    "    ax.set_yticks(y_ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.6 Dataset\n",
    "Data에서 batch를 분리하는 get_data_batch와<br>\n",
    "dataset를 생성하는 dataset_generator를 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_batch(data, batch_idx):\n",
    "    global n_batch, batch_size\n",
    "    ### Start\n",
    "    if batch_idx is n_batch -1:\n",
    "        batch = \n",
    "    else:\n",
    "        batch = \n",
    "    return batch\n",
    "    ### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(x_dict):\n",
    "    ### Start\n",
    "    x_data = np.random.normal()\n",
    "    x_data_noise = x_data + \n",
    "    \n",
    "    if x_dict['direction'] > 0:\n",
    "        y_data = (x_data_noise > x_dict['cutoff']).astype(np.int)\n",
    "    else:\n",
    "        y_data = (x_data_noise < x_dict['cutoff']).astype(np.int)\n",
    "    \n",
    "    data = np.zeros()\n",
    "    data = np.hstack()\n",
    "    return data\n",
    "    ### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.7\n",
    "모듈화한 dataset_generator를 통해서 dataset을 생성합니다<br><br>\n",
    "\"\"\"<br>\n",
    "mean: 0<br>\n",
    "std: 1<br>\n",
    "n_sample: 100<br>\n",
    "noise_factor: 0.5<br>\n",
    "cutoff: 0<br>\n",
    "direction: 1<br>\n",
    "\"\"\"<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict =  {'mean': , 'std': , 'n_sample': ,\n",
    "            'noise_factor': ,\n",
    "            'cutoff': , 'direction': }\n",
    "\n",
    "data = dataset_generator(x_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.8\n",
    "model과 BinaryCrossEntropy 객체를 생성합니다<br>\n",
    "batch_size는 8로 설정하고<br>\n",
    "iter_idx: 0으로 초기화하고<br>\n",
    "check_freq:5로 초기화합니다<br>\n",
    "epochs는 500 lr은 0.05로 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start\n",
    "batch_size = \n",
    "n_batch = \n",
    "\n",
    "model =  \n",
    "BCE_Cost =\n",
    "\n",
    "th_accum = \n",
    "cost_list = []\n",
    "epochs, lr =  \n",
    "iter_idx, check_freq =\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.9 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx)\n",
    "        X,Y =  batch[:,1], batch[:,-1]\n",
    "\n",
    "        Pred = model.forward(X)\n",
    "        J = BCE_Cost.forward(Y, Pred)\n",
    "\n",
    "        dPred = BCE_Cost.backward()\n",
    "        model.backward(dPred, lr)\n",
    "\n",
    "        result_tracker()\n",
    "result_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output** \n",
    "<img src='./img_9/9_13.png' width = 700>\n",
    "<img src='./img_9/9_14.png' width = 700>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
