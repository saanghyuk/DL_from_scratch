{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.5 Multi-variate Linear Regression\n",
    "\n",
    "## Programming Assignment.5-05 MVLR with N_Samples\n",
    "MVLR을 학습시키는데 2차원의 input이 아닌 N차원의 input을 통해서 이용하여 학습합니다\n",
    "model은\n",
    "$$\\hat{y} = \\theta_{5}x_{5} + \\theta_{4}x_{4} + \\theta_{3}x_{3} + \\theta_{2}x_{2} + \\theta_{1}x_{1} + \\theta_{0}$$\n",
    "\n",
    "이고, loss는 square error를 사용하기 때문에\n",
    "$$\\mathcal{L} = (y - \\hat{y})^{2}$$\n",
    "가 됩니다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import basic_nodes as nodes \n",
    "\n",
    "import os\n",
    "import sys\n",
    "utils_path = os.path.dirname(os.path.abspath(__name__)) + '/../utils/'\n",
    "if utils_path not in sys.path:    \n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "from LR_dataset_generator import LR_dataset_generator\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 dataset이\n",
    "$$y = 3x_{5} + 7x_{4} + 5x_{3} + 4x_{2} + 3x_{1}  - 1$$\n",
    "에서부터 만들어지고,<br> $x_{5}$$x_{4}$$x_{3}$$x_{2}$,$x_{1}$는 standard normal distribution에서부터 만들어지는 코드입니다.\n",
    "feature_dim 의 경우 5가 되고<br>\n",
    "sample의 개수는 1000개로 설정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Start Your Code(Learning Preparation) #####\n",
    "coefficient_list = []\n",
    "data_gen = LR_dataset_generator(feature_dim =  , n_sample = )\n",
    "data_gen.set_coefficient(coefficient_list)\n",
    "distribution_params = {\n",
    "    \n",
    "                      }\n",
    "##### End Your Code(Learning Preparation) #####\n",
    "data_gen.set_distribution_params(distribution_params)\n",
    "x_data, y_data = data_gen.make_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PA 5_04와 마찬가지로 node들을 배열로 생성하고<br>\n",
    "Hyperparameter들을 설정합니다<br>\n",
    "<br>\n",
    "학습 조건은 다음과 같습니다.<br>\n",
    "- $\\theta_{5}, \\theta_{4}, \\theta_{3}, \\theta_{2}, \\theta_{1}, \\theta_{0} = 0.1, 0.1, 0.1$\n",
    "- learning rate = 0.00005\n",
    "- iterations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Start Your Code(Learning Preparation) #####\n",
    "feature_dim = \n",
    "node1 = \n",
    "node2 = \n",
    "node3 =\n",
    "node4 = \n",
    "\n",
    "th_list = []\n",
    "\n",
    "lr = \n",
    "epochs = \n",
    "##### End Your Code(Learning Preparation) #####\n",
    "\n",
    "th_accum = np.array(th_list).reshape(-1, 1)\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data_idx, (X, y) in enumerate(zip(x_data, y_data)):\n",
    "        #Forward Propagation start\n",
    "        z1_list = [None] * (feature_dim + 1)\n",
    "        z2_list, dz2_list, dz1_list, dth_list = z1_list.copy(), z1_list.copy(), z1_list.copy(), z1_list.copy()\n",
    "        \n",
    "        for node_idx in range(1, feature_dim + 1):\n",
    "            z1_list[node_idx] = \n",
    "        \n",
    "        z2_list[1] =\n",
    "        for node_idx in range(2, feature_dim + 1):\n",
    "            z2_list[node_idx] = \n",
    "        z3 = \n",
    "        loss =\n",
    "        #Forward Propagation end\n",
    "        \n",
    "        #Backward Propagation start\n",
    "        dz3 = \n",
    "        _, dz2_last =\n",
    "        dz2_list[-1] = dz2_last\n",
    "        \n",
    "        for node_idx in reversed(range(1, feature_dim + 1)):\n",
    "            dz2, dz1 = \n",
    "            dz2_list[node_idx - 1] =\n",
    "            dz1_list[node_idx] = \n",
    "        \n",
    "        dth_list[0] = dz2_list[0]\n",
    "        for node_idx in reversed(range(1, feature_dim + 1)):\n",
    "            dth, _ = \n",
    "            dth_list[node_idx] =\n",
    "        #Backward Propagation end\n",
    "        \n",
    "\n",
    "        for th_idx in range(len(th_list)):\n",
    "            th_list[th_idx] = th_list[th_idx] - lr*dth_list[th_idx]\n",
    "        th_next = np.array(th_list).reshape(-1, 1)\n",
    "        th_accum = np.hstack((th_accum, th_next))\n",
    "        loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (40, 20))\n",
    "\n",
    "for i in range(feature_dim + 1):\n",
    "    ax[0].plot(th_accum[i], label = r'$\\theta_{%d}$'%i,\n",
    "               linewidth = 5)\n",
    "ax[1].plot(loss_list)\n",
    "ax[0].legend(loc = 'lower right',\n",
    "            fontsize = 30)\n",
    "ax[0].tick_params(axis = 'both', labelsize = 30)\n",
    "ax[1].tick_params(axis = 'both', labelsize = 30)\n",
    "\n",
    "ax[0].set_title(r'$\\vec{\\theta}$', fontsize = 40)\n",
    "ax[1].set_title('Loss', fontsize = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "<img src='./imgs/5_05_1.png' width = 800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ML': conda)",
   "language": "python",
   "name": "python37664bitmlconda63d4d036f3b243269c474d4202f7e655"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
