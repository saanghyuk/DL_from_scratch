{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.5 Multi-Variate Linear Regression\n",
    "\n",
    "## Programming Assignment.5-06 MVLR for several samples\n",
    "PA 5_06에서는 data sample을 여러개 사용하는 mini-batch를 이용하여<br>\n",
    "PA 5_05에서 학습했던 N차원의 input에 대한 Learning하는 방법을 할 것입니다<br><br>\n",
    "진행과정은 다음과 같습니다<br><br>\n",
    "1.Data Sample Generation<br>\n",
    "2.Mini-batch Preparation<br>\n",
    "3.Basic node <br>\n",
    "4.Hyperparameter<br>\n",
    "5.Learning with mini-batch<br>\n",
    "6.Visualization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import basic_nodes as nodes\n",
    "import os\n",
    "import sys\n",
    "utils_path = os.path.dirname(os.path.abspath(__name__)) + '/../utils/'\n",
    "if utils_path not in sys.path:    \n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "\n",
    "from LR_dataset_generator import LR_dataset_generator\n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(0)\n",
    "\n",
    "def get_data_batch(dataset, batch_idx, batch_size, n_batch):\n",
    "    if batch_idx is n_batch -1:\n",
    "        batch = dataset[batch_idx*batch_size:]\n",
    "    else:\n",
    "        batch = dataset[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Sample Generation\n",
    "$\\hat{y} = \\theta_{3}x_{3} + \\theta_{2}x_{2} + \\theta_{1}x_{1} + \\theta_{0}$<br> 위와 같은 모델을 사용하며<br><br>\n",
    "$y = x_{3} + 4x_{2} + 2x_{1}  + 5$<br> Data Sample은 위의 식을 통해서 생성합니다<br>\n",
    "mean은 0 std은 1로 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Start Your Code(Dataset Setting) #####\n",
    "coefficient_list = []\n",
    "distribution_params = {\n",
    "    \n",
    "}\n",
    "##### End Your Code(Dataset Setting) #####\n",
    "\n",
    "\n",
    "##### Start Your Code(Dataset Generation) #####\n",
    "\n",
    "\n",
    "##### End Your Code(Dataset Generation) #####\n",
    "x_data, y_data = data_gen.make_dataset()\n",
    "dataset = np.hstack((x_data,y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Mini-batch Preparation\n",
    "mini-batch에 관련된 변수들을 설정합니다\n",
    "* batch_size 8\n",
    "* batch_idx  0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start code\n",
    "feature_dim = \n",
    "batch_size = \n",
    "batch_idx = \n",
    "### End code\n",
    "n_batch = int(np.ceil(dataset.shape[0]/batch_size))\n",
    "\n",
    "batch = get_data_batch(dataset, batch_idx,batch_size, n_batch)\n",
    "print(\"batch.shape : \", batch.shape)\n",
    "X, Y = batch[:,:-1], batch[:,-1]\n",
    "print(\"X.shape : \", X.shape)\n",
    "print(\"Y.shape : \", Y.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "batch.shape : (8, 5)<br>\n",
    "X.shape : (8, 4)<br>\n",
    "Y.shape : (8,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic node \n",
    "다음은 필요한 Node 들을 선언합니다<br>\n",
    "PA 5_05까지와는 달리 mini-batch방식으로 진행하기 때문에<br>\n",
    "mean_node가 추가로 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = [None] + [nodes.mul_node() for _ in range(feature_dim)]\n",
    "node2 = [None] + [nodes.plus_node() for _ in range(feature_dim)]\n",
    "node3 = nodes.minus_node()\n",
    "node4 = nodes.square_node()\n",
    "node5 = nodes.mean_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Hyperparameter\n",
    "Hyperparameter들을 설정해줍니다\n",
    "* Learning Rate 0.01\n",
    "* epochs 30\n",
    "* $\\theta_{3}, \\theta_{2}, \\theta_{1}, \\theta_{0}$ 초기값    =     0.1  0.1  0.1  0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Start Your Code(Learning Preparation) #####\n",
    "lr = \n",
    "epochs = \n",
    "Th_list = []\n",
    "\n",
    "##### End Your Code(Learning Preparation) #####\n",
    "\n",
    "th_accum = np.array(Th_list).reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Learning with mini-batch\n",
    "PA 5_05에서 진행했던 N차원 input에 대한 Learning을<br>\n",
    "mini-batch방식으로 진행할 것이다<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(dataset)\n",
    "    for batch_idx in range(n_batch):\n",
    "        ##### Start Your Code(Batch Extraction) #####\n",
    "        batch = get_data_batch(dataset, batch_idx, batch_size, n_batch)\n",
    "        X, Y = batch[:,:-1], batch[:,-1]\n",
    "        \n",
    "        #Forward Propagation start\n",
    "        Z1_list = [None] * (feature_dim + 1)\n",
    "        Z2_list = Z1_list.copy()\n",
    "        dZ1_list, dZ2_list = Z1_list.copy(), Z1_list.copy()\n",
    "        dTh_list = dZ1_list.copy()\n",
    "        for node_idx in range(1, feature_dim + 1):\n",
    "            Z1_list[node_idx] = \n",
    "        \n",
    "        Z2_list[1] = \n",
    "        for node_idx in range(2, feature_dim + 1):\n",
    "            Z2_list[node_idx] = \n",
    "        Z3 = \n",
    "        Z4 = \n",
    "        J = \n",
    "        #Forward Propagation end\n",
    "        \n",
    "        #Backward Propagation start\n",
    "        dZ4 = \n",
    "        dZ3 = \n",
    "        _, dZ2_last =\n",
    "        dZ2_list[-1] = \n",
    "        \n",
    "        for node_idx in reversed(range(1, feature_dim + 1)):\n",
    "            dZ2, dZ1 = \n",
    "            dZ2_list[node_idx - 1] =\n",
    "            dZ1_list[node_idx] = \n",
    "        \n",
    "        dTh_list[0] = dZ2_list[0]\n",
    "        for node_idx in reversed(range(1, feature_dim + 1)):\n",
    "            dTh, _ = \n",
    "            dTh_list[node_idx] = \n",
    "        #Backward Propagation end\n",
    "        \n",
    "\n",
    "        for th_idx in range(len(Th_list)):\n",
    "            Th_list[th_idx] = Th_list[th_idx] - lr*np.sum(dTh_list[th_idx])\n",
    "        th_next = np.array(Th_list).reshape(-1, 1)\n",
    "        th_accum = np.hstack((th_accum, th_next))\n",
    "        cost_list.append(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (20, 20))\n",
    "\n",
    "for i in range(feature_dim + 1):\n",
    "    ax[0].plot(th_accum[i], label = r'$\\theta_{%d}$'%i,\n",
    "               linewidth = 5)\n",
    "ax[1].plot(cost_list)\n",
    "ax[0].legend(loc = 'lower right',\n",
    "            fontsize = 30)\n",
    "ax[0].tick_params(axis = 'both', labelsize = 30)\n",
    "ax[1].tick_params(axis = 'both', labelsize = 30)\n",
    "\n",
    "ax[0].set_title(r'$\\vec{\\theta}$', fontsize = 40)\n",
    "ax[1].set_title('Cost', fontsize = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "<img src='./imgs/5_06_1.png' width = 800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
